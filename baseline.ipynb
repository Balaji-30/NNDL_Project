{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc36e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from medmnist import ChestMNIST\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781a591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce GTX 1060\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a25940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation: converts to tensor and scales pixels to [0,1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Already converts [H, W] to [1, H, W] for grayscale images\n",
    "])\n",
    "\n",
    "# Load the ChestMNIST training and test sets (size=64)\n",
    "train_dataset = ChestMNIST(split='train', download=True, transform=transform, size=64)\n",
    "test_dataset  = ChestMNIST(split='test', download=True, transform=transform, size=64)\n",
    "val_dataset  = ChestMNIST(split='val', download=True, transform=transform, size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1521c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestMNISTMultiLabel(Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.base_dataset[idx]  # label is a numpy array of length 14\n",
    "        label = torch.tensor(label.astype(np.float32))\n",
    "        return img, label\n",
    "\n",
    "# Wrap the datasets\n",
    "train_data = ChestMNISTMultiLabel(train_dataset)\n",
    "val_data   = ChestMNISTMultiLabel(val_dataset)\n",
    "test_data  = ChestMNISTMultiLabel(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a3e61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3d6fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChestMNISTMultiLabelCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=16384, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ChestMNISTMultiLabelCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChestMNISTMultiLabelCNN, self).__init__()\n",
    "        # Input shape: (B, 1, 64, 64)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # -> (B, 32, 64, 64)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)                           # -> halves spatial dims\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # -> (B, 64, 32, 32)\n",
    "        # After another pooling, spatial size becomes 16x16: (B,64,16,16)\n",
    "        self.fc1   = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2   = nn.Linear(128, 14)  # 14 outputs for 14 labels\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 32, 32, 32)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 64, 16, 16)\n",
    "        x = x.view(x.size(0), -1)             # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))        # Sigmoid: independent probability for each class\n",
    "        return x\n",
    "\n",
    "model = ChestMNISTMultiLabelCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20d2c556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.1783 - Val Loss: 0.1717\n",
      "Epoch 2/50 - Train Loss: 0.1721 - Val Loss: 0.1696\n",
      "Epoch 3/50 - Train Loss: 0.1688 - Val Loss: 0.1676\n",
      "Epoch 4/50 - Train Loss: 0.1665 - Val Loss: 0.1659\n",
      "Epoch 5/50 - Train Loss: 0.1641 - Val Loss: 0.1656\n",
      "Epoch 6/50 - Train Loss: 0.1618 - Val Loss: 0.1664\n",
      "Epoch 7/50 - Train Loss: 0.1593 - Val Loss: 0.1660\n",
      "Epoch 8/50 - Train Loss: 0.1568 - Val Loss: 0.1669\n",
      "Early stopping triggered after 8 epochs\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()  # Binary Cross-Entropy for multi-label outputs\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and early stopping parameters\n",
    "num_epochs = 50         # Maximum number of epochs\n",
    "patience = 3            # Stop if no improvement in val loss for 3 consecutive epochs\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Check for improvement; if not, increase counter and possibly early stop\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef668513",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        all_preds.append(outputs.cpu())\n",
    "        all_labels.append(targets.cpu())\n",
    "\n",
    "# Stack predictions & labels into full batches\n",
    "import torch\n",
    "all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "all_labels = torch.cat(all_labels, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be69f463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Overall Classification Report *******\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.01      0.01      2420\n",
      "           1       0.51      0.04      0.08       582\n",
      "           2       0.58      0.04      0.08      2754\n",
      "           3       0.54      0.01      0.03      3938\n",
      "           4       0.20      0.00      0.00      1133\n",
      "           5       0.00      0.00      0.00      1335\n",
      "           6       0.00      0.00      0.00       242\n",
      "           7       0.25      0.01      0.01      1089\n",
      "           8       0.00      0.00      0.00       957\n",
      "           9       0.33      0.00      0.00       413\n",
      "          10       0.00      0.00      0.00       509\n",
      "          11       0.00      0.00      0.00       362\n",
      "          12       0.00      0.00      0.00       734\n",
      "          13       0.00      0.00      0.00        42\n",
      "\n",
      "   micro avg       0.52      0.01      0.03     16510\n",
      "   macro avg       0.20      0.01      0.02     16510\n",
      "weighted avg       0.34      0.01      0.03     16510\n",
      " samples avg       0.01      0.01      0.01     16510\n",
      "\n",
      "\n",
      "******* Overall AUC Scores *******\n",
      "Macro AUC: 0.727\n",
      "Micro AUC: 0.814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Binarize predictions (threshold at 0.5)\n",
    "binarized_preds = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "print(\"******* Overall Classification Report *******\")\n",
    "print(classification_report(all_labels, binarized_preds, zero_division=0))\n",
    "\n",
    "# Compute overall AUCs\n",
    "macro_auc = roc_auc_score(all_labels, all_preds, average='macro')\n",
    "micro_auc = roc_auc_score(all_labels, all_preds, average='micro')\n",
    "print(f\"\\n******* Overall AUC Scores *******\")\n",
    "print(f\"Macro AUC: {macro_auc:.3f}\")\n",
    "print(f\"Micro AUC: {micro_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebdb414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import glob\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class SyntheticPneumoniaDataset(Dataset):\n",
    "    def __init__(self, image_dir, img_size=64):\n",
    "        self.image_paths = sorted(glob.glob(f\"{image_dir}/*.png\"))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert('L')  # grayscale\n",
    "        img = self.transform(img)\n",
    "\n",
    "        label = torch.zeros(14, dtype=torch.float32)  # ðŸ‘ˆ Must be a Tensor!\n",
    "        label[6] = 1.0\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bed08fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([14]) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "synthetic_dataset = SyntheticPneumoniaDataset(\"augmented/pneumonia\")\n",
    "img, label = synthetic_dataset[0]\n",
    "print(type(img), img.shape)\n",
    "print(type(label), label.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ebe596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia confidence on synthetic images:\n",
      "Mean: 0.5059\n",
      "Max:  0.5872\n",
      "Min:  0.5001\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "probabilities = []\n",
    "\n",
    "for img, _ in synthetic_dataset:\n",
    "    img_tensor = img.unsqueeze(0).to(device)  # shape: (1, 1, 64, 64)\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(img_tensor))\n",
    "    probabilities.append(output[0, 6].item())  # confidence for pneumonia\n",
    "\n",
    "print(\"Pneumonia confidence on synthetic images:\")\n",
    "print(f\"Mean: {np.mean(probabilities):.4f}\")\n",
    "print(f\"Max:  {np.max(probabilities):.4f}\")\n",
    "print(f\"Min:  {np.min(probabilities):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7192db26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia Confidence Stats:\n",
      "Mean (all): 0.5027\n",
      "Mean (pneumonia): 0.5050\n",
      "Mean (non-pneumonia): 0.5026\n",
      "\n",
      "AUC: 0.6990409227108905\n",
      "Precision: 0.012, Recall: 1.000, F1: 0.023\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_probs = []\n",
    "val_labels = []\n",
    "\n",
    "for img, label in val_loader:\n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(img))  # keep sigmoid here if using logits\n",
    "\n",
    "    val_probs.append(output[:, 6].cpu())     # pneumonia confidence\n",
    "    val_labels.append(label[:, 6].cpu())     # ground truth pneumonia label\n",
    "\n",
    "val_probs = torch.cat(val_probs).numpy()\n",
    "val_labels = torch.cat(val_labels).numpy()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score\n",
    "\n",
    "print(\"Pneumonia Confidence Stats:\")\n",
    "print(f\"Mean (all): {val_probs.mean():.4f}\")\n",
    "print(f\"Mean (pneumonia): {val_probs[val_labels == 1].mean():.4f}\")\n",
    "print(f\"Mean (non-pneumonia): {val_probs[val_labels == 0].mean():.4f}\")\n",
    "\n",
    "print(\"\\nAUC:\", roc_auc_score(val_labels, val_probs))\n",
    "\n",
    "# Optional: see how many cases pass 0.5 threshold\n",
    "binary_preds = val_probs >= 0.5\n",
    "precision = (binary_preds[val_labels == 1].sum()) / max(binary_preds.sum(), 1)\n",
    "recall = (binary_preds[val_labels == 1].sum()) / max((val_labels == 1).sum(), 1)\n",
    "f1 = 2 * precision * recall / max((precision + recall), 1e-8)\n",
    "\n",
    "print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
