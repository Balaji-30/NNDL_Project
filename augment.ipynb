{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0d2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from medmnist import ChestMNIST\n",
    "from pytorch_fid import fid_score\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a64c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_channels)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        out += x  # Skip connection\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd51f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorIncreasedChannels(nn.Module):\n",
    "    def __init__(self, latent_dim, embedding_dim, num_classes, img_channels, img_size):\n",
    "        super(GeneratorIncreasedChannels, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, embedding_dim)\n",
    "        # Keep the same scaling factor: downsampled size will be img_size//4\n",
    "        self.init_size = img_size // 4  \n",
    "        # Increase the number of channels in the first fully connected layer to 256 instead of 128\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim + embedding_dim, 256 * self.init_size * self.init_size)\n",
    "        )\n",
    "        \n",
    "        # Initial upsampling block – now working with 256 channels\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Upsample(scale_factor=2),  # Upsample from init_size to init_size*2\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256, 0.8),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Add a couple of Residual Blocks; these work on 256 channels\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            ResidualBlock(256)\n",
    "        )\n",
    "        \n",
    "        # Final blocks: upsample and reduce channels to produce the final image\n",
    "        self.final_blocks = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),  # Upsample to full image resolution\n",
    "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, img_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()  # Tanh activation yields outputs in [-1, 1]\n",
    "        )\n",
    "        \n",
    "    def forward(self, noise, labels):\n",
    "        # Embed the labels\n",
    "        label_input = self.label_embedding(labels)\n",
    "        # Concatenate noise and label embedding along the last dimension\n",
    "        gen_input = torch.cat((noise, label_input), dim=-1)\n",
    "        out = self.fc(gen_input)\n",
    "        # Reshape to a feature map of shape (batch, 256, init_size, init_size)\n",
    "        out = out.view(out.shape[0], 256, self.init_size, self.init_size)\n",
    "        out = self.conv_blocks(out)\n",
    "        out = self.residual_blocks(out)\n",
    "        img = self.final_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628a0be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneratorIncreasedChannels(\n",
       "  (label_embedding): Embedding(2, 10)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=110, out_features=65536, bias=True)\n",
       "  )\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(256, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "  )\n",
       "  (residual_blocks): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (final_blocks): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PNEUMONIA_LABEL = 1\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "latent_dim = 100\n",
    "embedding_dim = 10\n",
    "num_classes = 2  # 0: non-pneumonia, 1: pneumonia\n",
    "img_size = 64\n",
    "img_channels = 1  # Grayscale images\n",
    "\n",
    "\n",
    "\n",
    "# Load generator\n",
    "generator = GeneratorIncreasedChannels(\n",
    "    latent_dim=latent_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_classes=num_classes,\n",
    "    img_channels=img_channels,\n",
    "    img_size=img_size\n",
    ").to(DEVICE)\n",
    "generator.load_state_dict(torch.load(\"best_rlrgenerator.pth\", map_location=DEVICE))\n",
    "generator.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f35e3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# NUM_IMAGES = 20000  # adjust as needed\n",
    "# labels = torch.full((NUM_IMAGES,), PNEUMONIA_LABEL, dtype=torch.long).to(DEVICE)\n",
    "# noise = torch.randn(NUM_IMAGES, latent_dim).to(DEVICE)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     gen_imgs = generator(noise, labels).cpu().squeeze(1).numpy()  # (B, H, W)\n",
    "\n",
    "# generated_images = [(img, PNEUMONIA_LABEL) for img in gen_imgs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c6c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def generate_pneumonia_images(generator, num_images, batch_size, latent_dim, label_idx, device):\n",
    "    generator.eval()\n",
    "    generated_images = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, num_images, batch_size):\n",
    "            curr_batch = min(batch_size, num_images - start)\n",
    "            noise = torch.randn(curr_batch, latent_dim).to(device)\n",
    "            labels = torch.full((curr_batch,), label_idx, dtype=torch.long).to(device)\n",
    "\n",
    "            gen_imgs = generator(noise, labels).cpu().squeeze(1).numpy()  # (B, H, W)\n",
    "            generated_images.extend([(img, label_idx) for img in gen_imgs])\n",
    "\n",
    "    return generated_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30474cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated 20000 pneumonia images.\n"
     ]
    }
   ],
   "source": [
    "PNEUMONIA_LABEL = 1\n",
    "latent_dim = 100\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generated_images = generate_pneumonia_images(\n",
    "    generator=generator,\n",
    "    num_images=20000,\n",
    "    batch_size=64,       # adjust if you want\n",
    "    latent_dim=latent_dim,\n",
    "    label_idx=PNEUMONIA_LABEL,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(f\"✅ Generated {len(generated_images)} pneumonia images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ecd1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self, base_dataset, pneumonia_index=6):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.indices = [i for i in range(len(self.base_dataset)) if int(self.base_dataset[i][1][pneumonia_index]) == 1]\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        img, _ = self.base_dataset[real_idx]\n",
    "        # Convert image range from [0,1] to [-1,1] to match generator output (using Tanh)\n",
    "        img = img * 2 - 1\n",
    "        return img, 1  # pneumonia label is 1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "batch_size = 16  # or 8, 32 – small and efficient\n",
    "full_train_dataset = ChestMNIST(split='train', download=True, transform=transform, size=img_size)\n",
    "pneumonia_dataset = PneumoniaDataset(full_train_dataset, pneumonia_index=6)\n",
    "pneumonia_loader = DataLoader(pneumonia_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd2d59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pneumonia_images = []\n",
    "\n",
    "for img_batch, _ in pneumonia_loader:\n",
    "    img_batch = (img_batch + 1) / 2  # convert [-1, 1] → [0, 1]\n",
    "\n",
    "    for i in range(img_batch.size(0)):\n",
    "        img_tensor = img_batch[i]  # shape: (1, 64, 64)\n",
    "        img_2d = img_tensor.squeeze(0)  # remove channel dimension → (64, 64)\n",
    "        img_np = img_2d.numpy()  # convert to NumPy\n",
    "        assert img_np.shape == (64, 64), f\"Got shape {img_np.shape}\"  # ✅ safety check\n",
    "        real_pneumonia_images.append(img_np)\n",
    "\n",
    "    if len(real_pneumonia_images) >= 500:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aea3c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered 6000 high-quality images (top 30% by SSIM)\n"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def avg_ssim(gen_img, real_imgs):\n",
    "    return np.mean([\n",
    "        ssim(gen_img, real_img, data_range=1.0) for real_img in real_imgs\n",
    "    ])\n",
    "\n",
    "# Ensure real pneumonia images are a list of (64, 64) arrays\n",
    "real_pneumonia = list(real_pneumonia_images)  # shape: (64, 64), values in [0, 1]\n",
    "\n",
    "ssim_scores = []\n",
    "\n",
    "# ⬅️ FIXED: Unpack (img, label) tuple\n",
    "for img, _ in generated_images:\n",
    "    sample_real = random.sample(real_pneumonia, k=min(5, len(real_pneumonia)))\n",
    "    score = avg_ssim(img, sample_real)\n",
    "    ssim_scores.append(score)\n",
    "\n",
    "# Keep top 30% most SSIM-similar\n",
    "threshold = np.percentile(ssim_scores, 70)\n",
    "filtered_images = [\n",
    "    img for (img, _), score in zip(generated_images, ssim_scores) if score >= threshold\n",
    "]\n",
    "\n",
    "print(f\"✅ Filtered {len(filtered_images)} high-quality images (top 30% by SSIM)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff4978",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m generated_images:\n\u001b[32m     13\u001b[39m     sample_real = random.sample(real_pneumonia, k=\u001b[38;5;28mmin\u001b[39m(\u001b[32m5\u001b[39m, \u001b[38;5;28mlen\u001b[39m(real_pneumonia)))\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     score = \u001b[43mavg_ssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     ssim_scores.append(score)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Keep top 30% most similar\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mavg_ssim\u001b[39m\u001b[34m(gen_img, real_imgs)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mavg_ssim\u001b[39m(gen_img, real_imgs):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(\u001b[43m[\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_range\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreal_img\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreal_imgs\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mavg_ssim\u001b[39m(gen_img, real_imgs):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean([\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         \u001b[43mssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_range\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m real_img \u001b[38;5;129;01min\u001b[39;00m real_imgs\n\u001b[32m      6\u001b[39m     ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1Projects\\GAN\\venv\\Lib\\site-packages\\skimage\\metrics\\_structural_similarity.py:118\u001b[39m, in \u001b[36mstructural_similarity\u001b[39m\u001b[34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructural_similarity\u001b[39m(\n\u001b[32m     16\u001b[39m     im1,\n\u001b[32m     17\u001b[39m     im2,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     **kwargs,\n\u001b[32m     26\u001b[39m ):\n\u001b[32m     27\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    Compute the mean structural similarity index between two images.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    Please pay attention to the `data_range` parameter with floating-point images.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[43mcheck_shape_equality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     float_type = _supported_float_type(im1.dtype)\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    122\u001b[39m         \u001b[38;5;66;03m# loop over channels\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1Projects\\GAN\\venv\\Lib\\site-packages\\skimage\\_shared\\utils.py:626\u001b[39m, in \u001b[36mcheck_shape_equality\u001b[39m\u001b[34m(*images)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that all images have the same shape\"\"\"\u001b[39;00m\n\u001b[32m    625\u001b[39m image0 = images[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(image0.shape == image.shape \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images[\u001b[32m1\u001b[39m:]):\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mInput images must have the same dimensions.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\1Projects\\GAN\\venv\\Lib\\site-packages\\skimage\\_shared\\utils.py:626\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that all images have the same shape\"\"\"\u001b[39;00m\n\u001b[32m    625\u001b[39m image0 = images[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mimage0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m == image.shape \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images[\u001b[32m1\u001b[39m:]):\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mInput images must have the same dimensions.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# from skimage.metrics import structural_similarity as ssim\n",
    "# import random\n",
    "# def avg_ssim(gen_img, real_imgs):\n",
    "#     return np.mean([\n",
    "#         ssim(gen_img, real_img, data_range=1.0) for real_img in real_imgs\n",
    "#     ])\n",
    "\n",
    "# real_pneumonia = real_pneumonia_images\n",
    "# real_pneumonia = list(real_pneumonia)  # forces conversion\n",
    "\n",
    "# ssim_scores = []\n",
    "# for img in generated_images:\n",
    "#     sample_real = random.sample(real_pneumonia, k=min(5, len(real_pneumonia)))\n",
    "\n",
    "#     score = avg_ssim(img, sample_real)\n",
    "#     ssim_scores.append(score)\n",
    "\n",
    "# # Keep top 30% most similar\n",
    "# threshold = np.percentile(ssim_scores, 70)\n",
    "# filtered_images = [img for img, score in zip(generated_images, ssim_scores) if score >= threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d6106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: (64, 64)\n",
      "Real example: (64, 64)\n"
     ]
    }
   ],
   "source": [
    "# print(\"Generated:\", img.shape)\n",
    "# print(\"Real example:\", real_pneumonia[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d8c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssim_scores = []\n",
    "# for img in gen_imgs:\n",
    "#     sample_real = random.sample(real_pneumonia, k=min(5, len(real_pneumonia)))\n",
    "#     score = avg_ssim(img, sample_real)\n",
    "#     ssim_scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb5e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 19 high-quality images.\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Keep top 30% most similar images\n",
    "# threshold = np.percentile(ssim_scores, 70)\n",
    "\n",
    "# filtered_images = [img for img, score in zip(gen_imgs, ssim_scores) if score >= threshold]\n",
    "# print(f\"Selected {len(filtered_images)} high-quality images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d66c2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "save_dir = \"augmented/pneumonia\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for i, img in enumerate(filtered_images):\n",
    "    # Step 1: Normalize from [-1, 1] to [0, 1]\n",
    "    img = (img + 1) / 2 if img.min() < 0 else img\n",
    "\n",
    "    # Step 2: Clip to avoid out-of-range values\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    # Step 3: Convert to uint8\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "\n",
    "    # Step 4: Save as PNG\n",
    "    imageio.imwrite(os.path.join(save_dir, f\"gen_{i}.png\"), img_uint8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
