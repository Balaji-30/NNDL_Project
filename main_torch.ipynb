{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3312bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from medmnist import ChestMNIST\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115e3cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce GTX 1060\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ee29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation: converts to tensor and scales pixels to [0,1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Already converts [H, W] to [1, H, W] for grayscale images\n",
    "])\n",
    "\n",
    "# Load the ChestMNIST training and test sets (size=64)\n",
    "train_dataset = ChestMNIST(split='train', download=True, transform=transform, size=64)\n",
    "test_dataset  = ChestMNIST(split='test', download=True, transform=transform, size=64)\n",
    "val_dataset  = ChestMNIST(split='val', download=True, transform=transform, size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c54e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestMNISTMultiLabel(Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.base_dataset[idx]  # label is a numpy array of length 14\n",
    "        label = torch.tensor(label.astype(np.float32))\n",
    "        return img, label\n",
    "\n",
    "# Wrap the datasets\n",
    "train_data = ChestMNISTMultiLabel(train_dataset)\n",
    "val_data   = ChestMNISTMultiLabel(val_dataset)\n",
    "test_data  = ChestMNISTMultiLabel(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca4a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda24bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChestMNISTMultiLabelCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=16384, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ChestMNISTMultiLabelCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChestMNISTMultiLabelCNN, self).__init__()\n",
    "        # Input shape: (B, 1, 64, 64)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # -> (B, 32, 64, 64)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)                           # -> halves spatial dims\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # -> (B, 64, 32, 32)\n",
    "        # After another pooling, spatial size becomes 16x16: (B,64,16,16)\n",
    "        self.fc1   = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2   = nn.Linear(128, 14)  # 14 outputs for 14 labels\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 32, 32, 32)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 64, 16, 16)\n",
    "        x = x.view(x.size(0), -1)             # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))        # Sigmoid: independent probability for each class\n",
    "        return x\n",
    "\n",
    "model = ChestMNISTMultiLabelCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3619eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.1779 - Val Loss: 0.1704\n",
      "Epoch 2/50 - Train Loss: 0.1713 - Val Loss: 0.1682\n",
      "Epoch 3/50 - Train Loss: 0.1681 - Val Loss: 0.1682\n",
      "Epoch 4/50 - Train Loss: 0.1657 - Val Loss: 0.1659\n",
      "Epoch 5/50 - Train Loss: 0.1629 - Val Loss: 0.1650\n",
      "Epoch 6/50 - Train Loss: 0.1601 - Val Loss: 0.1650\n",
      "Epoch 7/50 - Train Loss: 0.1571 - Val Loss: 0.1668\n",
      "Epoch 8/50 - Train Loss: 0.1536 - Val Loss: 0.1666\n",
      "Early stopping triggered after 8 epochs\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()  # Binary Cross-Entropy for multi-label outputs\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and early stopping parameters\n",
    "num_epochs = 50         # Maximum number of epochs\n",
    "patience = 3            # Stop if no improvement in val loss for 3 consecutive epochs\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Check for improvement; if not, increase counter and possibly early stop\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "709f430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Overall Classification Report *******\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.950     0.997     0.973    297552\n",
      "         1.0      0.461     0.050     0.090     16510\n",
      "\n",
      "    accuracy                          0.947    314062\n",
      "   macro avg      0.706     0.523     0.532    314062\n",
      "weighted avg      0.924     0.947     0.926    314062\n",
      "\n",
      "******* Overall Confusion Matrix *******\n",
      "[[296587    965]\n",
      " [ 15683    827]]\n",
      "******* Overall AUC Scores *******\n",
      "Overall Macro AUC: 0.733\n",
      "Overall Micro AUC: 0.818\n",
      "\n",
      "******* Per-Class Metrics *******\n",
      "\n",
      "Classification Report for Atelectasis:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.895     0.992     0.941     20013\n",
      "         1.0      0.376     0.041     0.074      2420\n",
      "\n",
      "    accuracy                          0.889     22433\n",
      "   macro avg      0.636     0.516     0.507     22433\n",
      "weighted avg      0.839     0.889     0.848     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19849   164]\n",
      " [ 2321    99]]\n",
      "AUC for Atelectasis: 0.726\n",
      "\n",
      "Classification Report for Cardiomegaly:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.975     0.998     0.987     21851\n",
      "         1.0      0.423     0.052     0.092       582\n",
      "\n",
      "    accuracy                          0.974     22433\n",
      "   macro avg      0.699     0.525     0.539     22433\n",
      "weighted avg      0.961     0.974     0.963     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21810    41]\n",
      " [  552    30]]\n",
      "AUC for Cardiomegaly: 0.835\n",
      "\n",
      "Classification Report for Effusion:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.895     0.975     0.933     19679\n",
      "         1.0      0.505     0.184     0.269      2754\n",
      "\n",
      "    accuracy                          0.878     22433\n",
      "   macro avg      0.700     0.579     0.601     22433\n",
      "weighted avg      0.847     0.878     0.852     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19183   496]\n",
      " [ 2248   506]]\n",
      "AUC for Effusion: 0.811\n",
      "\n",
      "Classification Report for Infiltration:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.829     0.988     0.901     18495\n",
      "         1.0      0.426     0.042     0.076      3938\n",
      "\n",
      "    accuracy                          0.822     22433\n",
      "   macro avg      0.628     0.515     0.489     22433\n",
      "weighted avg      0.758     0.822     0.757     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18273   222]\n",
      " [ 3773   165]]\n",
      "AUC for Infiltration: 0.660\n",
      "\n",
      "Classification Report for Mass:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.950     0.999     0.974     21300\n",
      "         1.0      0.406     0.011     0.022      1133\n",
      "\n",
      "    accuracy                          0.949     22433\n",
      "   macro avg      0.678     0.505     0.498     22433\n",
      "weighted avg      0.923     0.949     0.926     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21281    19]\n",
      " [ 1120    13]]\n",
      "AUC for Mass: 0.686\n",
      "\n",
      "Classification Report for Nodule:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.940     1.000     0.969     21098\n",
      "         1.0      0.000     0.000     0.000      1335\n",
      "\n",
      "    accuracy                          0.940     22433\n",
      "   macro avg      0.470     0.500     0.485     22433\n",
      "weighted avg      0.885     0.940     0.912     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21098     0]\n",
      " [ 1335     0]]\n",
      "AUC for Nodule: 0.606\n",
      "\n",
      "Classification Report for Pneumonia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.989     1.000     0.995     22191\n",
      "         1.0      0.000     0.000     0.000       242\n",
      "\n",
      "    accuracy                          0.989     22433\n",
      "   macro avg      0.495     0.500     0.497     22433\n",
      "weighted avg      0.979     0.989     0.984     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22191     0]\n",
      " [  242     0]]\n",
      "AUC for Pneumonia: 0.643\n",
      "\n",
      "Classification Report for Pneumothorax:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.952     0.999     0.975     21344\n",
      "         1.0      0.393     0.010     0.020      1089\n",
      "\n",
      "    accuracy                          0.951     22433\n",
      "   macro avg      0.672     0.505     0.497     22433\n",
      "weighted avg      0.925     0.951     0.929     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21327    17]\n",
      " [ 1078    11]]\n",
      "AUC for Pneumothorax: 0.746\n",
      "\n",
      "Classification Report for Consolidation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.957     1.000     0.978     21476\n",
      "         1.0      0.000     0.000     0.000       957\n",
      "\n",
      "    accuracy                          0.957     22433\n",
      "   macro avg      0.479     0.500     0.489     22433\n",
      "weighted avg      0.916     0.957     0.936     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21476     0]\n",
      " [  957     0]]\n",
      "AUC for Consolidation: 0.743\n",
      "\n",
      "Classification Report for Edema:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.982     1.000     0.991     22020\n",
      "         1.0      0.200     0.002     0.005       413\n",
      "\n",
      "    accuracy                          0.981     22433\n",
      "   macro avg      0.591     0.501     0.498     22433\n",
      "weighted avg      0.967     0.981     0.972     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22016     4]\n",
      " [  412     1]]\n",
      "AUC for Edema: 0.852\n",
      "\n",
      "Classification Report for Emphysema:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.977     1.000     0.989     21924\n",
      "         1.0      0.000     0.000     0.000       509\n",
      "\n",
      "    accuracy                          0.977     22433\n",
      "   macro avg      0.489     0.500     0.494     22433\n",
      "weighted avg      0.955     0.977     0.966     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21924     0]\n",
      " [  509     0]]\n",
      "AUC for Emphysema: 0.726\n",
      "\n",
      "Classification Report for Fibrosis:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.984     1.000     0.992     22071\n",
      "         1.0      0.000     0.000     0.000       362\n",
      "\n",
      "    accuracy                          0.984     22433\n",
      "   macro avg      0.492     0.500     0.496     22433\n",
      "weighted avg      0.968     0.984     0.976     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22071     0]\n",
      " [  362     0]]\n",
      "AUC for Fibrosis: 0.707\n",
      "\n",
      "Classification Report for Pleural_Thickening:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.967     1.000     0.983     21699\n",
      "         1.0      0.500     0.003     0.005       734\n",
      "\n",
      "    accuracy                          0.967     22433\n",
      "   macro avg      0.734     0.501     0.494     22433\n",
      "weighted avg      0.952     0.967     0.951     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21697     2]\n",
      " [  732     2]]\n",
      "AUC for Pleural_Thickening: 0.690\n",
      "\n",
      "Classification Report for Hernia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.998     1.000     0.999     22391\n",
      "         1.0      0.000     0.000     0.000        42\n",
      "\n",
      "    accuracy                          0.998     22433\n",
      "   macro avg      0.499     0.500     0.500     22433\n",
      "weighted avg      0.996     0.998     0.997     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22391     0]\n",
      " [   42     0]]\n",
      "AUC for Hernia: 0.834\n",
      "\n",
      "******* Summary: AUC Per Class *******\n",
      "Atelectasis: 0.726\n",
      "Cardiomegaly: 0.835\n",
      "Effusion: 0.811\n",
      "Infiltration: 0.660\n",
      "Mass: 0.686\n",
      "Nodule: 0.606\n",
      "Pneumonia: 0.643\n",
      "Pneumothorax: 0.746\n",
      "Consolidation: 0.743\n",
      "Edema: 0.852\n",
      "Emphysema: 0.726\n",
      "Fibrosis: 0.707\n",
      "Pleural_Thickening: 0.690\n",
      "Hernia: 0.834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate on Test Set & Collect Predictions\n",
    "# -------------------------------\n",
    "\n",
    "model.eval()\n",
    "all_probs = []    # to store predicted probabilities\n",
    "all_preds = []    # to store thresholded (binary) predictions if needed for classification report\n",
    "all_targets = []  # to store true targets\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)  # outputs are probabilities because model returns torch.sigmoid(x)\n",
    "        all_probs.append(outputs.cpu().numpy())\n",
    "        \n",
    "        preds = (outputs > 0.5).float()  # Binary predictions for classification report and confusion matrix\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        \n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "all_probs = np.concatenate(all_probs, axis=0)    # shape: (n_samples, 14)\n",
    "all_preds = np.concatenate(all_preds, axis=0)      # shape: (n_samples, 14)\n",
    "all_targets = np.concatenate(all_targets, axis=0)  # shape: (n_samples, 14)\n",
    "\n",
    "# -------------------------------\n",
    "# Define Class Names (in order)\n",
    "# -------------------------------\n",
    "disease_labels = [\n",
    "    \"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\",\n",
    "    \"Mass\", \"Nodule\", \"Pneumonia\", \"Pneumothorax\", \"Consolidation\",\n",
    "    \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Overall (Global) Metrics\n",
    "# -------------------------------\n",
    "# For overall AUC, compute both micro and macro averages.\n",
    "try:\n",
    "    overall_auc_macro = roc_auc_score(all_targets, all_probs, average=\"macro\")\n",
    "except ValueError as e:\n",
    "    overall_auc_macro = None\n",
    "    print(\"Error computing overall macro AUC:\", e)\n",
    "\n",
    "try:\n",
    "    overall_auc_micro = roc_auc_score(all_targets, all_probs, average=\"micro\")\n",
    "except ValueError as e:\n",
    "    overall_auc_micro = None\n",
    "    print(\"Error computing overall micro AUC:\", e)\n",
    "\n",
    "# For overall classification report, flatten the arrays\n",
    "flat_targets = all_targets.flatten()\n",
    "flat_preds = all_preds.flatten()\n",
    "\n",
    "overall_report = classification_report(flat_targets, flat_preds, digits=3)\n",
    "overall_cm = confusion_matrix(flat_targets, flat_preds)\n",
    "\n",
    "print(\"******* Overall Classification Report *******\")\n",
    "print(overall_report)\n",
    "print(\"******* Overall Confusion Matrix *******\")\n",
    "print(overall_cm)\n",
    "print(\"******* Overall AUC Scores *******\")\n",
    "print(f\"Overall Macro AUC: {overall_auc_macro:.3f}\" if overall_auc_macro is not None else \"Overall Macro AUC: Error\")\n",
    "print(f\"Overall Micro AUC: {overall_auc_micro:.3f}\" if overall_auc_micro is not None else \"Overall Micro AUC: Error\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Per-Class Metrics\n",
    "# -------------------------------\n",
    "print(\"\\n******* Per-Class Metrics *******\")\n",
    "auc_per_class = {}\n",
    "for i, label_name in enumerate(disease_labels):\n",
    "    print(f\"\\nClassification Report for {label_name}:\")\n",
    "    print(classification_report(all_targets[:, i], all_preds[:, i], digits=3))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_targets[:, i], all_preds[:, i]))\n",
    "    \n",
    "    # Compute ROC AUC for each class using the probabilities.\n",
    "    try:\n",
    "        auc = roc_auc_score(all_targets[:, i], all_probs[:, i])\n",
    "    except ValueError as e:\n",
    "        auc = None\n",
    "        print(f\"Error computing AUC for {label_name}: {e}\")\n",
    "    auc_per_class[label_name] = auc\n",
    "    print(f\"AUC for {label_name}: {auc:.3f}\" if auc is not None else \"AUC computation error\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Summary of Per-Class AUC Scores\n",
    "# -------------------------------\n",
    "print(\"\\n******* Summary: AUC Per Class *******\")\n",
    "for label, auc in auc_per_class.items():\n",
    "    if auc is not None:\n",
    "        print(f\"{label}: {auc:.3f}\")\n",
    "    else:\n",
    "        print(f\"{label}: AUC computation error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684c5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import glob\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class SyntheticPneumoniaDataset(Dataset):\n",
    "    def __init__(self, image_dir, img_size=64):\n",
    "        self.image_paths = sorted(glob.glob(f\"{image_dir}/*.png\"))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])  # [-1, 1] range\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert('L')  # grayscale\n",
    "        img = self.transform(img)\n",
    "\n",
    "        label = torch.zeros(14, dtype=torch.float32)  # ðŸ‘ˆ Must be a Tensor!\n",
    "        label[6] = 1.0\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac694e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TorchChestMNIST(Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.base_dataset[idx]\n",
    "        # label is a numpy array â†’ convert to tensor\n",
    "        return img, torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ae2165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medmnist import ChestMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Tanh-style\n",
    "])\n",
    "\n",
    "base_dataset = ChestMNIST(split='train', download=True, transform=transform, size=64)\n",
    "real_train_dataset = TorchChestMNIST(base_dataset)  # âœ… fixes the label format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad907b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 64, 64])\n",
      "<class 'torch.Tensor'> torch.Size([14]) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "synthetic_dataset = SyntheticPneumoniaDataset(\"augmented/pneumonia\")\n",
    "img, label = synthetic_dataset[0]\n",
    "print(type(img), img.shape)\n",
    "print(type(label), label.shape, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b12a58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "augmented_train_dataset = ConcatDataset([real_train_dataset, synthetic_dataset])\n",
    "augmented_train_loader = DataLoader(augmented_train_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0548154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.1695 - Val Loss: 0.1823\n",
      "Epoch 2/50 - Train Loss: 0.1571 - Val Loss: 0.1759\n",
      "Epoch 3/50 - Train Loss: 0.1527 - Val Loss: 0.1784\n",
      "Epoch 4/50 - Train Loss: 0.1488 - Val Loss: 0.1809\n",
      "Epoch 5/50 - Train Loss: 0.1445 - Val Loss: 0.1796\n",
      "Early stopping triggered after 5 epochs\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()  # Binary Cross-Entropy for multi-label outputs\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and early stopping parameters\n",
    "num_epochs = 50         # Maximum number of epochs\n",
    "patience = 3            # Stop if no improvement in val loss for 3 consecutive epochs\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in augmented_train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(augmented_train_loader.dataset)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Check for improvement; if not, increase counter and possibly early stop\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6be35ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        all_preds.append(outputs.cpu())\n",
    "        all_labels.append(targets.cpu())\n",
    "\n",
    "# Stack predictions & labels into full batches\n",
    "import torch\n",
    "all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "all_labels = torch.cat(all_labels, dim=0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89f66e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Overall Classification Report *******\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2420\n",
      "           1       0.00      0.00      0.00       582\n",
      "           2       0.36      0.03      0.06      2754\n",
      "           3       0.00      0.00      0.00      3938\n",
      "           4       0.00      0.00      0.00      1133\n",
      "           5       0.00      0.00      0.00      1335\n",
      "           6       0.00      0.00      0.00       242\n",
      "           7       0.00      0.00      0.00      1089\n",
      "           8       0.00      0.00      0.00       957\n",
      "           9       0.00      0.00      0.00       413\n",
      "          10       0.00      0.00      0.00       509\n",
      "          11       0.00      0.00      0.00       362\n",
      "          12       0.00      0.00      0.00       734\n",
      "          13       0.00      0.00      0.00        42\n",
      "\n",
      "   micro avg       0.33      0.01      0.01     16510\n",
      "   macro avg       0.03      0.00      0.00     16510\n",
      "weighted avg       0.06      0.01      0.01     16510\n",
      " samples avg       0.00      0.00      0.00     16510\n",
      "\n",
      "\n",
      "******* Overall AUC Scores *******\n",
      "Macro AUC: 0.629\n",
      "Micro AUC: 0.760\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Binarize predictions (threshold at 0.5)\n",
    "binarized_preds = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "print(\"******* Overall Classification Report *******\")\n",
    "print(classification_report(all_labels, binarized_preds, zero_division=0))\n",
    "\n",
    "# Compute overall AUCs\n",
    "macro_auc = roc_auc_score(all_labels, all_preds, average='macro')\n",
    "micro_auc = roc_auc_score(all_labels, all_preds, average='micro')\n",
    "print(f\"\\n******* Overall AUC Scores *******\")\n",
    "print(f\"Macro AUC: {macro_auc:.3f}\")\n",
    "print(f\"Micro AUC: {micro_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aca2ef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real label 0: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Real label 1: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Real label 2: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Real label 3: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Real label 4: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "real_dataset = TorchChestMNIST(ChestMNIST(split='train', transform=transform, size=64))\n",
    "\n",
    "for i in range(5):\n",
    "    img, label = real_dataset[i]\n",
    "    print(f\"Real label {i}:\", label)\n",
    "    assert isinstance(label, torch.Tensor), \"Label is not tensor\"\n",
    "    assert label.shape == (14,), \"Label shape is not (14,)\"\n",
    "    assert label.dtype == torch.float32, \"Label dtype is not float\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3640ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Overall Classification Report *******\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.948     0.999     0.973    297552\n",
      "         1.0      0.331     0.005     0.010     16510\n",
      "\n",
      "    accuracy                          0.947    314062\n",
      "   macro avg      0.639     0.502     0.491    314062\n",
      "weighted avg      0.915     0.947     0.922    314062\n",
      "\n",
      "******* Overall Confusion Matrix *******\n",
      "[[297382    170]\n",
      " [ 16426     84]]\n",
      "******* Overall AUC Scores *******\n",
      "Overall Macro AUC: 0.629\n",
      "Overall Micro AUC: 0.760\n",
      "\n",
      "******* Per-Class Metrics *******\n",
      "\n",
      "Classification Report for Atelectasis:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.892     1.000     0.943     20013\n",
      "         1.0      0.000     0.000     0.000      2420\n",
      "\n",
      "    accuracy                          0.892     22433\n",
      "   macro avg      0.446     0.500     0.471     22433\n",
      "weighted avg      0.796     0.892     0.841     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20010     3]\n",
      " [ 2420     0]]\n",
      "AUC for Atelectasis: 0.642\n",
      "\n",
      "Classification Report for Cardiomegaly:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.974     1.000     0.987     21851\n",
      "         1.0      0.000     0.000     0.000       582\n",
      "\n",
      "    accuracy                          0.974     22433\n",
      "   macro avg      0.487     0.500     0.493     22433\n",
      "weighted avg      0.949     0.974     0.961     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21851     0]\n",
      " [  582     0]]\n",
      "AUC for Cardiomegaly: 0.756\n",
      "\n",
      "Classification Report for Effusion:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.880     0.992     0.933     19679\n",
      "         1.0      0.361     0.031     0.056      2754\n",
      "\n",
      "    accuracy                          0.874     22433\n",
      "   macro avg      0.620     0.511     0.494     22433\n",
      "weighted avg      0.816     0.874     0.825     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19530   149]\n",
      " [ 2670    84]]\n",
      "AUC for Effusion: 0.708\n",
      "\n",
      "Classification Report for Infiltration:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.824     1.000     0.904     18495\n",
      "         1.0      0.000     0.000     0.000      3938\n",
      "\n",
      "    accuracy                          0.824     22433\n",
      "   macro avg      0.412     0.500     0.452     22433\n",
      "weighted avg      0.680     0.824     0.745     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18495     0]\n",
      " [ 3938     0]]\n",
      "AUC for Infiltration: 0.608\n",
      "\n",
      "Classification Report for Mass:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.949     1.000     0.974     21300\n",
      "         1.0      0.000     0.000     0.000      1133\n",
      "\n",
      "    accuracy                          0.949     22433\n",
      "   macro avg      0.475     0.500     0.487     22433\n",
      "weighted avg      0.902     0.949     0.925     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21300     0]\n",
      " [ 1133     0]]\n",
      "AUC for Mass: 0.561\n",
      "\n",
      "Classification Report for Nodule:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.940     1.000     0.969     21098\n",
      "         1.0      0.000     0.000     0.000      1335\n",
      "\n",
      "    accuracy                          0.940     22433\n",
      "   macro avg      0.470     0.500     0.485     22433\n",
      "weighted avg      0.885     0.940     0.912     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21098     0]\n",
      " [ 1335     0]]\n",
      "AUC for Nodule: 0.553\n",
      "\n",
      "Classification Report for Pneumonia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.989     0.999     0.994     22191\n",
      "         1.0      0.000     0.000     0.000       242\n",
      "\n",
      "    accuracy                          0.988     22433\n",
      "   macro avg      0.495     0.500     0.497     22433\n",
      "weighted avg      0.979     0.988     0.983     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22173    18]\n",
      " [  242     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Pneumonia: 0.605\n",
      "\n",
      "Classification Report for Pneumothorax:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.951     1.000     0.975     21344\n",
      "         1.0      0.000     0.000     0.000      1089\n",
      "\n",
      "    accuracy                          0.951     22433\n",
      "   macro avg      0.476     0.500     0.488     22433\n",
      "weighted avg      0.905     0.951     0.928     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21344     0]\n",
      " [ 1089     0]]\n",
      "AUC for Pneumothorax: 0.615\n",
      "\n",
      "Classification Report for Consolidation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.957     1.000     0.978     21476\n",
      "         1.0      0.000     0.000     0.000       957\n",
      "\n",
      "    accuracy                          0.957     22433\n",
      "   macro avg      0.479     0.500     0.489     22433\n",
      "weighted avg      0.916     0.957     0.936     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21476     0]\n",
      " [  957     0]]\n",
      "AUC for Consolidation: 0.699\n",
      "\n",
      "Classification Report for Edema:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.982     1.000     0.991     22020\n",
      "         1.0      0.000     0.000     0.000       413\n",
      "\n",
      "    accuracy                          0.982     22433\n",
      "   macro avg      0.491     0.500     0.495     22433\n",
      "weighted avg      0.964     0.982     0.972     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22020     0]\n",
      " [  413     0]]\n",
      "AUC for Edema: 0.760\n",
      "\n",
      "Classification Report for Emphysema:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.977     1.000     0.989     21924\n",
      "         1.0      0.000     0.000     0.000       509\n",
      "\n",
      "    accuracy                          0.977     22433\n",
      "   macro avg      0.489     0.500     0.494     22433\n",
      "weighted avg      0.955     0.977     0.966     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21924     0]\n",
      " [  509     0]]\n",
      "AUC for Emphysema: 0.613\n",
      "\n",
      "Classification Report for Fibrosis:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.984     1.000     0.992     22071\n",
      "         1.0      0.000     0.000     0.000       362\n",
      "\n",
      "    accuracy                          0.984     22433\n",
      "   macro avg      0.492     0.500     0.496     22433\n",
      "weighted avg      0.968     0.984     0.976     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22071     0]\n",
      " [  362     0]]\n",
      "AUC for Fibrosis: 0.610\n",
      "\n",
      "Classification Report for Pleural_Thickening:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.967     1.000     0.983     21699\n",
      "         1.0      0.000     0.000     0.000       734\n",
      "\n",
      "    accuracy                          0.967     22433\n",
      "   macro avg      0.484     0.500     0.492     22433\n",
      "weighted avg      0.936     0.967     0.951     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21699     0]\n",
      " [  734     0]]\n",
      "AUC for Pleural_Thickening: 0.567\n",
      "\n",
      "Classification Report for Hernia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.998     1.000     0.999     22391\n",
      "         1.0      0.000     0.000     0.000        42\n",
      "\n",
      "    accuracy                          0.998     22433\n",
      "   macro avg      0.499     0.500     0.500     22433\n",
      "weighted avg      0.996     0.998     0.997     22433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22391     0]\n",
      " [   42     0]]\n",
      "AUC for Hernia: 0.515\n",
      "\n",
      "******* Summary: AUC Per Class *******\n",
      "Atelectasis: 0.642\n",
      "Cardiomegaly: 0.756\n",
      "Effusion: 0.708\n",
      "Infiltration: 0.608\n",
      "Mass: 0.561\n",
      "Nodule: 0.553\n",
      "Pneumonia: 0.605\n",
      "Pneumothorax: 0.615\n",
      "Consolidation: 0.699\n",
      "Edema: 0.760\n",
      "Emphysema: 0.613\n",
      "Fibrosis: 0.610\n",
      "Pleural_Thickening: 0.567\n",
      "Hernia: 0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\1Projects\\GAN\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluate on Test Set & Collect Predictions\n",
    "# -------------------------------\n",
    "\n",
    "model.eval()\n",
    "all_probs = []    # to store predicted probabilities\n",
    "all_preds = []    # to store thresholded (binary) predictions if needed for classification report\n",
    "all_targets = []  # to store true targets\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)  # outputs are probabilities because model returns torch.sigmoid(x)\n",
    "        all_probs.append(outputs.cpu().numpy())\n",
    "        \n",
    "        preds = (outputs > 0.5).float()  # Binary predictions for classification report and confusion matrix\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        \n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "all_probs = np.concatenate(all_probs, axis=0)    # shape: (n_samples, 14)\n",
    "all_preds = np.concatenate(all_preds, axis=0)      # shape: (n_samples, 14)\n",
    "all_targets = np.concatenate(all_targets, axis=0)  # shape: (n_samples, 14)\n",
    "\n",
    "# -------------------------------\n",
    "# Define Class Names (in order)\n",
    "# -------------------------------\n",
    "disease_labels = [\n",
    "    \"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\",\n",
    "    \"Mass\", \"Nodule\", \"Pneumonia\", \"Pneumothorax\", \"Consolidation\",\n",
    "    \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Overall (Global) Metrics\n",
    "# -------------------------------\n",
    "# For overall AUC, compute both micro and macro averages.\n",
    "try:\n",
    "    overall_auc_macro = roc_auc_score(all_targets, all_probs, average=\"macro\")\n",
    "except ValueError as e:\n",
    "    overall_auc_macro = None\n",
    "    print(\"Error computing overall macro AUC:\", e)\n",
    "\n",
    "try:\n",
    "    overall_auc_micro = roc_auc_score(all_targets, all_probs, average=\"micro\")\n",
    "except ValueError as e:\n",
    "    overall_auc_micro = None\n",
    "    print(\"Error computing overall micro AUC:\", e)\n",
    "\n",
    "# For overall classification report, flatten the arrays\n",
    "flat_targets = all_targets.flatten()\n",
    "flat_preds = all_preds.flatten()\n",
    "\n",
    "overall_report = classification_report(flat_targets, flat_preds, digits=3)\n",
    "overall_cm = confusion_matrix(flat_targets, flat_preds)\n",
    "\n",
    "print(\"******* Overall Classification Report *******\")\n",
    "print(overall_report)\n",
    "print(\"******* Overall Confusion Matrix *******\")\n",
    "print(overall_cm)\n",
    "print(\"******* Overall AUC Scores *******\")\n",
    "print(f\"Overall Macro AUC: {overall_auc_macro:.3f}\" if overall_auc_macro is not None else \"Overall Macro AUC: Error\")\n",
    "print(f\"Overall Micro AUC: {overall_auc_micro:.3f}\" if overall_auc_micro is not None else \"Overall Micro AUC: Error\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Per-Class Metrics\n",
    "# -------------------------------\n",
    "print(\"\\n******* Per-Class Metrics *******\")\n",
    "auc_per_class = {}\n",
    "for i, label_name in enumerate(disease_labels):\n",
    "    print(f\"\\nClassification Report for {label_name}:\")\n",
    "    print(classification_report(all_targets[:, i], all_preds[:, i], digits=3))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(all_targets[:, i], all_preds[:, i]))\n",
    "    \n",
    "    # Compute ROC AUC for each class using the probabilities.\n",
    "    try:\n",
    "        auc = roc_auc_score(all_targets[:, i], all_probs[:, i])\n",
    "    except ValueError as e:\n",
    "        auc = None\n",
    "        print(f\"Error computing AUC for {label_name}: {e}\")\n",
    "    auc_per_class[label_name] = auc\n",
    "    print(f\"AUC for {label_name}: {auc:.3f}\" if auc is not None else \"AUC computation error\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Summary of Per-Class AUC Scores\n",
    "# -------------------------------\n",
    "print(\"\\n******* Summary: AUC Per Class *******\")\n",
    "for label, auc in auc_per_class.items():\n",
    "    if auc is not None:\n",
    "        print(f\"{label}: {auc:.3f}\")\n",
    "    else:\n",
    "        print(f\"{label}: AUC computation error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3446330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic label 0: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Synthetic label 1: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Synthetic label 2: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Synthetic label 3: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Synthetic label 4: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "synthetic_dataset = SyntheticPneumoniaDataset(\"augmented/pneumonia\")\n",
    "\n",
    "for i in range(5):\n",
    "    img, label = synthetic_dataset[i]\n",
    "    print(f\"Synthetic label {i}:\", label)\n",
    "    assert label.shape == (14,), \"Label shape is wrong\"\n",
    "    assert label.dtype == torch.float32, \"Label dtype is not float32\"\n",
    "    assert label[6] == 1 and label.sum() == 1, \"Pneumonia not correctly one-hot\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e99bb51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real label 0: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Real label 1: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Real label 2: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Real label 3: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Real label 4: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "real_dataset = TorchChestMNIST(ChestMNIST(split='train', transform=transform, size=64))\n",
    "\n",
    "for i in range(5):\n",
    "    img, label = real_dataset[i]\n",
    "    print(f\"Real label {i}:\", label)\n",
    "    assert isinstance(label, torch.Tensor), \"Label is not tensor\"\n",
    "    assert label.shape == (14,), \"Label shape is not (14,)\"\n",
    "    assert label.dtype == torch.float32, \"Label dtype is not float\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "018eaf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "probabilities = []\n",
    "\n",
    "for img, _ in synthetic_dataset:\n",
    "    img_tensor = img.unsqueeze(0).to(device)  # shape: (1, 1, 64, 64)\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(img_tensor))\n",
    "    probabilities.append(output[0, 6].item())  # confidence for pneumonia\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f066dd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia confidence on synthetic images:\n",
      "Mean: 0.7308\n",
      "Max:  0.7311\n",
      "Min:  0.6114\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Pneumonia confidence on synthetic images:\")\n",
    "print(f\"Mean: {np.mean(probabilities):.4f}\")\n",
    "print(f\"Max:  {np.max(probabilities):.4f}\")\n",
    "print(f\"Min:  {np.min(probabilities):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f40e25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_probs = []\n",
    "val_labels = []\n",
    "\n",
    "for img, label in val_loader:\n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(img))  # keep sigmoid here if using logits\n",
    "\n",
    "    val_probs.append(output[:, 6].cpu())     # pneumonia confidence\n",
    "    val_labels.append(label[:, 6].cpu())     # ground truth pneumonia label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6e2ca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia Confidence Stats:\n",
      "Mean (all): 0.5041\n",
      "Mean (pneumonia): 0.5065\n",
      "Mean (non-pneumonia): 0.5041\n",
      "\n",
      "AUC: 0.5758370307873237\n",
      "Precision: 0.012, Recall: 1.000, F1: 0.023\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "val_probs = torch.cat(val_probs).numpy()\n",
    "val_labels = torch.cat(val_labels).numpy()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score\n",
    "\n",
    "print(\"Pneumonia Confidence Stats:\")\n",
    "print(f\"Mean (all): {val_probs.mean():.4f}\")\n",
    "print(f\"Mean (pneumonia): {val_probs[val_labels == 1].mean():.4f}\")\n",
    "print(f\"Mean (non-pneumonia): {val_probs[val_labels == 0].mean():.4f}\")\n",
    "\n",
    "print(\"\\nAUC:\", roc_auc_score(val_labels, val_probs))\n",
    "\n",
    "# Optional: see how many cases pass 0.5 threshold\n",
    "binary_preds = val_probs >= 0.5\n",
    "precision = (binary_preds[val_labels == 1].sum()) / max(binary_preds.sum(), 1)\n",
    "recall = (binary_preds[val_labels == 1].sum()) / max((val_labels == 1).sum(), 1)\n",
    "f1 = 2 * precision * recall / max((precision + recall), 1e-8)\n",
    "\n",
    "print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d99c9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChestMNISTMultiLabelCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=16384, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ChestMNISTMultiLabelCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChestMNISTMultiLabelCNN, self).__init__()\n",
    "        # Input shape: (B, 1, 64, 64)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # -> (B, 32, 64, 64)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)                           # -> halves spatial dims\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # -> (B, 64, 32, 32)\n",
    "        # After another pooling, spatial size becomes 16x16: (B,64,16,16)\n",
    "        self.fc1   = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2   = nn.Linear(128, 14)  # 14 outputs for 14 labels\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 32, 32, 32)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 64, 16, 16)\n",
    "        x = x.view(x.size(0), -1)             # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)  # logits only!\n",
    "\n",
    "\n",
    "model = ChestMNISTMultiLabelCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dad5ffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.2135 - Val Loss: 0.2189\n",
      "Epoch 2/50 - Train Loss: 0.1937 - Val Loss: 0.2206\n",
      "Epoch 3/50 - Train Loss: 0.1889 - Val Loss: 0.2383\n",
      "Epoch 4/50 - Train Loss: 0.1840 - Val Loss: 0.2174\n",
      "Epoch 5/50 - Train Loss: 0.1779 - Val Loss: 0.2349\n",
      "Epoch 6/50 - Train Loss: 0.1701 - Val Loss: 0.2300\n",
      "Epoch 7/50 - Train Loss: 0.1605 - Val Loss: 0.2494\n",
      "Early stopping triggered after 7 epochs\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# ---- Loss and optimizer ----\n",
    "pos_weights = torch.ones(14).to(device)\n",
    "pos_weights[6] = 20.0\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ---- Training loop ----\n",
    "num_epochs = 50\n",
    "patience = 3\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in augmented_train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device).float()  # <- make sure labels are float\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # model now returns raw logits\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(augmented_train_loader.dataset)\n",
    "\n",
    "    # ---- Validation phase ----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device).float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # ---- Early stopping ----\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d114106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Pneumonia Evaluation:\n",
      "AUC:      0.552\n",
      "Precision: 0.005\n",
      "Recall:    0.008\n",
      "F1-score:  0.006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "val_probs = []\n",
    "val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device).float()\n",
    "\n",
    "        outputs = torch.sigmoid(model(inputs))  # apply sigmoid manually\n",
    "        val_probs.append(outputs[:, 6].cpu())   # pneumonia confidence\n",
    "        val_labels.append(targets[:, 6].cpu())  # ground truth\n",
    "\n",
    "# Combine all batches\n",
    "val_probs = torch.cat(val_probs).numpy()\n",
    "val_labels = torch.cat(val_labels).numpy()\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(val_labels, val_probs)\n",
    "\n",
    "binary_preds = (val_probs >= 0.5).astype(int)\n",
    "tp = (binary_preds * val_labels).sum()\n",
    "fp = ((binary_preds == 1) & (val_labels == 0)).sum()\n",
    "fn = ((binary_preds == 0) & (val_labels == 1)).sum()\n",
    "\n",
    "precision = tp / max(tp + fp, 1)\n",
    "recall = tp / max(tp + fn, 1)\n",
    "f1 = 2 * precision * recall / max(precision + recall, 1e-8)\n",
    "\n",
    "print(\"ðŸ“Š Pneumonia Evaluation:\")\n",
    "print(f\"AUC:      {auc:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-score:  {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47d0d34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.1920 - Val Loss: 0.2097\n",
      "Epoch 2/50 - Train Loss: 0.1767 - Val Loss: 0.2149\n",
      "Epoch 3/50 - Train Loss: 0.1668 - Val Loss: 0.2284\n",
      "Epoch 4/50 - Train Loss: 0.1599 - Val Loss: 0.2348\n",
      "Early stopping triggered after 4 epochs\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# ---- Loss and optimizer ----\n",
    "pos_weights = torch.ones(14).to(device)\n",
    "pos_weights[6] = 20.0\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ---- Training loop ----\n",
    "num_epochs = 50\n",
    "patience = 3\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device).float()  # <- make sure labels are float\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # model now returns raw logits\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # ---- Validation phase ----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device).float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # ---- Early stopping ----\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faa4ce12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Pneumonia Evaluation:\n",
      "AUC:      0.633\n",
      "Precision: 0.027\n",
      "Recall:    0.120\n",
      "F1-score:  0.045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "val_probs = []\n",
    "val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device).float()\n",
    "\n",
    "        outputs = torch.sigmoid(model(inputs))  # apply sigmoid manually\n",
    "        val_probs.append(outputs[:, 6].cpu())   # pneumonia confidence\n",
    "        val_labels.append(targets[:, 6].cpu())  # ground truth\n",
    "\n",
    "# Combine all batches\n",
    "val_probs = torch.cat(val_probs).numpy()\n",
    "val_labels = torch.cat(val_labels).numpy()\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(val_labels, val_probs)\n",
    "\n",
    "binary_preds = (val_probs >= 0.5).astype(int)\n",
    "tp = (binary_preds * val_labels).sum()\n",
    "fp = ((binary_preds == 1) & (val_labels == 0)).sum()\n",
    "fn = ((binary_preds == 0) & (val_labels == 1)).sum()\n",
    "\n",
    "precision = tp / max(tp + fp, 1)\n",
    "recall = tp / max(tp + fn, 1)\n",
    "f1 = 2 * precision * recall / max(precision + recall, 1e-8)\n",
    "\n",
    "print(\"ðŸ“Š Pneumonia Evaluation:\")\n",
    "print(f\"AUC:      {auc:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1-score:  {f1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
